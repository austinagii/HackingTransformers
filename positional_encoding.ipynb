{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2b7519b-cef8-43c1-a8a9-7e2a0cab2b46",
   "metadata": {},
   "source": [
    "# Positional Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2067e2-7076-4257-8ec3-d85591eeba6d",
   "metadata": {},
   "source": [
    "During positional encoding, we want to add information to each token in the context window based on it's position within the window. The model can then this information to learn potential relationships between tokens based on their relative positions. The authors propose to do this by defining $PE$, a ($\\text{max\\_seq\\_len} \\times d_{model})$ tensor containing positional information for each token and then adding $PE$ to the tensor representing the context window. $\\it{PE}$ is defined according to the following formula:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "PE_{(pos, 2i)} &= sin(pos / 10000^{2i / d_{model}}), \\\\\n",
    "PE_{(pos, 2i+1)} &= cos(pos / 10000^{2i / d_{model}}) \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{where } pos =&\\in \\{ n \\in \\mathbb{Z} \\mid 0 \\leq n \\leq \\text{max\\_seq\\_len} \\}, \\\\\n",
    "                t =&\\in \\{ n \\in \\mathbb{Z} \\mid 0 \\leq n \\leq d_{model} / 2 \\}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "to make things easier to implement (or at least for me it's more obvious this way), we'll make a slight change to the formula:\n",
    "$$\n",
    "\\it{PE}_{(pos, i)} =\n",
    "\\begin{cases}\n",
    "& sin(pos / 10000^{2\\lfloor\\frac{i}{2}\\rfloor / d_{model}}), & \\text{if } i \\text{ is even}, \\\\\n",
    "& cos(pos / 10000^{2\\lfloor\\frac{i}{2}\\rfloor / d_{model}}), & \\text{if } i \\text{ is odd}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6ece134-2d46-42d8-806e-a51c6b987637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b2ac837-8289-455a-b5a2-125ccffff95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46502944-e463-4d3e-a5bc-96972e9a20e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 1.0000e+00, 1.0366e+00, 1.0366e+00, 1.0746e+00, 1.0746e+00,\n",
       "        1.1140e+00, 1.1140e+00, 1.1548e+00, 1.1548e+00, 1.1971e+00, 1.1971e+00,\n",
       "        1.2409e+00, 1.2409e+00, 1.2864e+00, 1.2864e+00, 1.3335e+00, 1.3335e+00,\n",
       "        1.3824e+00, 1.3824e+00, 1.4330e+00, 1.4330e+00, 1.4855e+00, 1.4855e+00,\n",
       "        1.5399e+00, 1.5399e+00, 1.5963e+00, 1.5963e+00, 1.6548e+00, 1.6548e+00,\n",
       "        1.7154e+00, 1.7154e+00, 1.7783e+00, 1.7783e+00, 1.8434e+00, 1.8434e+00,\n",
       "        1.9110e+00, 1.9110e+00, 1.9810e+00, 1.9810e+00, 2.0535e+00, 2.0535e+00,\n",
       "        2.1288e+00, 2.1288e+00, 2.2067e+00, 2.2067e+00, 2.2876e+00, 2.2876e+00,\n",
       "        2.3714e+00, 2.3714e+00, 2.4582e+00, 2.4582e+00, 2.5483e+00, 2.5483e+00,\n",
       "        2.6416e+00, 2.6416e+00, 2.7384e+00, 2.7384e+00, 2.8387e+00, 2.8387e+00,\n",
       "        2.9427e+00, 2.9427e+00, 3.0505e+00, 3.0505e+00, 3.1623e+00, 3.1623e+00,\n",
       "        3.2781e+00, 3.2781e+00, 3.3982e+00, 3.3982e+00, 3.5227e+00, 3.5227e+00,\n",
       "        3.6517e+00, 3.6517e+00, 3.7855e+00, 3.7855e+00, 3.9242e+00, 3.9242e+00,\n",
       "        4.0679e+00, 4.0679e+00, 4.2170e+00, 4.2170e+00, 4.3714e+00, 4.3714e+00,\n",
       "        4.5316e+00, 4.5316e+00, 4.6976e+00, 4.6976e+00, 4.8697e+00, 4.8697e+00,\n",
       "        5.0481e+00, 5.0481e+00, 5.2330e+00, 5.2330e+00, 5.4247e+00, 5.4247e+00,\n",
       "        5.6234e+00, 5.6234e+00, 5.8294e+00, 5.8294e+00, 6.0430e+00, 6.0430e+00,\n",
       "        6.2643e+00, 6.2643e+00, 6.4938e+00, 6.4938e+00, 6.7317e+00, 6.7317e+00,\n",
       "        6.9783e+00, 6.9783e+00, 7.2339e+00, 7.2339e+00, 7.4989e+00, 7.4989e+00,\n",
       "        7.7737e+00, 7.7737e+00, 8.0584e+00, 8.0584e+00, 8.3536e+00, 8.3536e+00,\n",
       "        8.6596e+00, 8.6596e+00, 8.9769e+00, 8.9769e+00, 9.3057e+00, 9.3057e+00,\n",
       "        9.6466e+00, 9.6466e+00, 1.0000e+01, 1.0000e+01, 1.0366e+01, 1.0366e+01,\n",
       "        1.0746e+01, 1.0746e+01, 1.1140e+01, 1.1140e+01, 1.1548e+01, 1.1548e+01,\n",
       "        1.1971e+01, 1.1971e+01, 1.2409e+01, 1.2409e+01, 1.2864e+01, 1.2864e+01,\n",
       "        1.3335e+01, 1.3335e+01, 1.3824e+01, 1.3824e+01, 1.4330e+01, 1.4330e+01,\n",
       "        1.4855e+01, 1.4855e+01, 1.5399e+01, 1.5399e+01, 1.5963e+01, 1.5963e+01,\n",
       "        1.6548e+01, 1.6548e+01, 1.7154e+01, 1.7154e+01, 1.7783e+01, 1.7783e+01,\n",
       "        1.8434e+01, 1.8434e+01, 1.9110e+01, 1.9110e+01, 1.9810e+01, 1.9810e+01,\n",
       "        2.0535e+01, 2.0535e+01, 2.1288e+01, 2.1288e+01, 2.2067e+01, 2.2067e+01,\n",
       "        2.2876e+01, 2.2876e+01, 2.3714e+01, 2.3714e+01, 2.4582e+01, 2.4582e+01,\n",
       "        2.5483e+01, 2.5483e+01, 2.6416e+01, 2.6416e+01, 2.7384e+01, 2.7384e+01,\n",
       "        2.8387e+01, 2.8387e+01, 2.9427e+01, 2.9427e+01, 3.0505e+01, 3.0505e+01,\n",
       "        3.1623e+01, 3.1623e+01, 3.2781e+01, 3.2781e+01, 3.3982e+01, 3.3982e+01,\n",
       "        3.5227e+01, 3.5227e+01, 3.6517e+01, 3.6517e+01, 3.7855e+01, 3.7855e+01,\n",
       "        3.9242e+01, 3.9242e+01, 4.0679e+01, 4.0679e+01, 4.2170e+01, 4.2170e+01,\n",
       "        4.3714e+01, 4.3714e+01, 4.5316e+01, 4.5316e+01, 4.6976e+01, 4.6976e+01,\n",
       "        4.8697e+01, 4.8697e+01, 5.0481e+01, 5.0481e+01, 5.2330e+01, 5.2330e+01,\n",
       "        5.4247e+01, 5.4247e+01, 5.6234e+01, 5.6234e+01, 5.8294e+01, 5.8294e+01,\n",
       "        6.0430e+01, 6.0430e+01, 6.2643e+01, 6.2643e+01, 6.4938e+01, 6.4938e+01,\n",
       "        6.7317e+01, 6.7317e+01, 6.9783e+01, 6.9783e+01, 7.2339e+01, 7.2339e+01,\n",
       "        7.4989e+01, 7.4989e+01, 7.7737e+01, 7.7737e+01, 8.0584e+01, 8.0584e+01,\n",
       "        8.3536e+01, 8.3536e+01, 8.6596e+01, 8.6596e+01, 8.9769e+01, 8.9769e+01,\n",
       "        9.3057e+01, 9.3057e+01, 9.6466e+01, 9.6466e+01, 1.0000e+02, 1.0000e+02,\n",
       "        1.0366e+02, 1.0366e+02, 1.0746e+02, 1.0746e+02, 1.1140e+02, 1.1140e+02,\n",
       "        1.1548e+02, 1.1548e+02, 1.1971e+02, 1.1971e+02, 1.2409e+02, 1.2409e+02,\n",
       "        1.2864e+02, 1.2864e+02, 1.3335e+02, 1.3335e+02, 1.3824e+02, 1.3824e+02,\n",
       "        1.4330e+02, 1.4330e+02, 1.4855e+02, 1.4855e+02, 1.5399e+02, 1.5399e+02,\n",
       "        1.5963e+02, 1.5963e+02, 1.6548e+02, 1.6548e+02, 1.7154e+02, 1.7154e+02,\n",
       "        1.7783e+02, 1.7783e+02, 1.8434e+02, 1.8434e+02, 1.9110e+02, 1.9110e+02,\n",
       "        1.9810e+02, 1.9810e+02, 2.0535e+02, 2.0535e+02, 2.1288e+02, 2.1288e+02,\n",
       "        2.2067e+02, 2.2067e+02, 2.2876e+02, 2.2876e+02, 2.3714e+02, 2.3714e+02,\n",
       "        2.4582e+02, 2.4582e+02, 2.5483e+02, 2.5483e+02, 2.6416e+02, 2.6416e+02,\n",
       "        2.7384e+02, 2.7384e+02, 2.8387e+02, 2.8387e+02, 2.9427e+02, 2.9427e+02,\n",
       "        3.0505e+02, 3.0505e+02, 3.1623e+02, 3.1623e+02, 3.2781e+02, 3.2781e+02,\n",
       "        3.3982e+02, 3.3982e+02, 3.5227e+02, 3.5227e+02, 3.6517e+02, 3.6517e+02,\n",
       "        3.7855e+02, 3.7855e+02, 3.9242e+02, 3.9242e+02, 4.0679e+02, 4.0679e+02,\n",
       "        4.2170e+02, 4.2170e+02, 4.3714e+02, 4.3714e+02, 4.5316e+02, 4.5316e+02,\n",
       "        4.6976e+02, 4.6976e+02, 4.8697e+02, 4.8697e+02, 5.0481e+02, 5.0481e+02,\n",
       "        5.2330e+02, 5.2330e+02, 5.4247e+02, 5.4247e+02, 5.6234e+02, 5.6234e+02,\n",
       "        5.8294e+02, 5.8294e+02, 6.0430e+02, 6.0430e+02, 6.2643e+02, 6.2643e+02,\n",
       "        6.4938e+02, 6.4938e+02, 6.7317e+02, 6.7317e+02, 6.9783e+02, 6.9783e+02,\n",
       "        7.2339e+02, 7.2339e+02, 7.4989e+02, 7.4989e+02, 7.7737e+02, 7.7737e+02,\n",
       "        8.0584e+02, 8.0584e+02, 8.3536e+02, 8.3536e+02, 8.6596e+02, 8.6596e+02,\n",
       "        8.9769e+02, 8.9769e+02, 9.3057e+02, 9.3057e+02, 9.6466e+02, 9.6466e+02,\n",
       "        1.0000e+03, 1.0000e+03, 1.0366e+03, 1.0366e+03, 1.0746e+03, 1.0746e+03,\n",
       "        1.1140e+03, 1.1140e+03, 1.1548e+03, 1.1548e+03, 1.1971e+03, 1.1971e+03,\n",
       "        1.2409e+03, 1.2409e+03, 1.2864e+03, 1.2864e+03, 1.3335e+03, 1.3335e+03,\n",
       "        1.3824e+03, 1.3824e+03, 1.4330e+03, 1.4330e+03, 1.4855e+03, 1.4855e+03,\n",
       "        1.5399e+03, 1.5399e+03, 1.5963e+03, 1.5963e+03, 1.6548e+03, 1.6548e+03,\n",
       "        1.7154e+03, 1.7154e+03, 1.7783e+03, 1.7783e+03, 1.8434e+03, 1.8434e+03,\n",
       "        1.9110e+03, 1.9110e+03, 1.9810e+03, 1.9810e+03, 2.0535e+03, 2.0535e+03,\n",
       "        2.1288e+03, 2.1288e+03, 2.2067e+03, 2.2067e+03, 2.2876e+03, 2.2876e+03,\n",
       "        2.3714e+03, 2.3714e+03, 2.4582e+03, 2.4582e+03, 2.5483e+03, 2.5483e+03,\n",
       "        2.6416e+03, 2.6416e+03, 2.7384e+03, 2.7384e+03, 2.8387e+03, 2.8387e+03,\n",
       "        2.9427e+03, 2.9427e+03, 3.0505e+03, 3.0505e+03, 3.1623e+03, 3.1623e+03,\n",
       "        3.2781e+03, 3.2781e+03, 3.3982e+03, 3.3982e+03, 3.5227e+03, 3.5227e+03,\n",
       "        3.6517e+03, 3.6517e+03, 3.7855e+03, 3.7855e+03, 3.9242e+03, 3.9242e+03,\n",
       "        4.0679e+03, 4.0679e+03, 4.2170e+03, 4.2170e+03, 4.3714e+03, 4.3714e+03,\n",
       "        4.5316e+03, 4.5316e+03, 4.6976e+03, 4.6976e+03, 4.8697e+03, 4.8697e+03,\n",
       "        5.0481e+03, 5.0481e+03, 5.2330e+03, 5.2330e+03, 5.4247e+03, 5.4247e+03,\n",
       "        5.6234e+03, 5.6234e+03, 5.8294e+03, 5.8294e+03, 6.0430e+03, 6.0430e+03,\n",
       "        6.2643e+03, 6.2643e+03, 6.4938e+03, 6.4938e+03, 6.7317e+03, 6.7317e+03,\n",
       "        6.9783e+03, 6.9783e+03, 7.2339e+03, 7.2339e+03, 7.4989e+03, 7.4989e+03,\n",
       "        7.7737e+03, 7.7737e+03, 8.0584e+03, 8.0584e+03, 8.3536e+03, 8.3536e+03,\n",
       "        8.6596e+03, 8.6596e+03, 8.9769e+03, 8.9769e+03, 9.3057e+03, 9.3057e+03,\n",
       "        9.6466e+03, 9.6466e+03])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias = torch.full((d_model,), 10_000, dtype=torch.float)\n",
    "indices = ((torch.arange(d_model) // 2) * 2) / d_model\n",
    "divisor = bias.pow(indices)\n",
    "divisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4218db9-f609-46e1-9787-c9b48399bb79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [1.0000e+00, 1.0000e+00, 9.6466e-01,  ..., 1.0746e-04, 1.0366e-04,\n",
       "         1.0366e-04],\n",
       "        [2.0000e+00, 2.0000e+00, 1.9293e+00,  ..., 2.1492e-04, 2.0733e-04,\n",
       "         2.0733e-04],\n",
       "        ...,\n",
       "        [1.0210e+03, 1.0210e+03, 9.8492e+02,  ..., 1.0972e-01, 1.0584e-01,\n",
       "         1.0584e-01],\n",
       "        [1.0220e+03, 1.0220e+03, 9.8588e+02,  ..., 1.0982e-01, 1.0594e-01,\n",
       "         1.0594e-01],\n",
       "        [1.0230e+03, 1.0230e+03, 9.8685e+02,  ..., 1.0993e-01, 1.0605e-01,\n",
       "         1.0605e-01]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len = 1024\n",
    "pos = torch.arange(max_seq_len, dtype=torch.float).view((-1, 1))\n",
    "freqs = pos / divisor\n",
    "freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c29bb08-3e9a-44ea-8a24-ab6a37ba42dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
       "          0.0000e+00,  1.0000e+00],\n",
       "        [ 8.4147e-01,  5.4030e-01,  8.2186e-01,  ...,  1.0000e+00,\n",
       "          1.0366e-04,  1.0000e+00],\n",
       "        [ 9.0930e-01, -4.1615e-01,  9.3641e-01,  ...,  1.0000e+00,\n",
       "          2.0733e-04,  1.0000e+00],\n",
       "        ...,\n",
       "        [ 1.7612e-02, -9.9984e-01, -9.9954e-01,  ...,  9.9399e-01,\n",
       "          1.0564e-01,  9.9440e-01],\n",
       "        [-8.3182e-01, -5.5504e-01, -5.4457e-01,  ...,  9.9398e-01,\n",
       "          1.0575e-01,  9.9439e-01],\n",
       "        [-9.1649e-01,  4.0007e-01,  3.7906e-01,  ...,  9.9396e-01,\n",
       "          1.0585e-01,  9.9438e-01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PE = torch.zeros((max_seq_len, d_model), dtype=torch.float)\n",
    "PE[:, 0::2] = torch.sin(freqs[:, 0::2])\n",
    "PE[:, 1::2] = torch.cos(freqs[:, 1::2])\n",
    "PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "218e35b1-0816-4732-911e-10eaa7a9eae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class PositionalEncode(nn.Module):\n",
    "    def __init__(self, max_seq_length: int = 1024, d_model: int = 512) -> None:\n",
    "        \"\"\"\n",
    "        Generates sinusoidal positional encodings.\n",
    "    \n",
    "        Parameters:\n",
    "            max_seq_len (int): Maximum sequence length.\n",
    "            d_model (int): Dimensionality of the model embeddings.\n",
    "    \n",
    "        Returns:\n",
    "            torch.Tensor: A tensor of shape (max_seq_len, d_model) containing \n",
    "                          the positional encodings.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Create position indices: pos = [0, 1, ..., max_seq_len-1]\n",
    "        pos_indices = torch.arange(max_seq_len, dtype=torch.float32)\n",
    "        \n",
    "        # Create dimension indices: dim = [0, 1, ..., d_model-1]\n",
    "        dim_indices = torch.arange(d_model, dtype=torch.float32)\n",
    "        \n",
    "        # Compute the scaling exponent: 2 * floor(dim/2) / d_model\n",
    "        exponent = ((dim_indices // 2) * 2) / d_model\n",
    "        \n",
    "        # Compute the denominator term: 10000^(exponent)\n",
    "        div_term = torch.pow(10000, exponent)\n",
    "        \n",
    "        # Compute the angle rates: pos / div_term\n",
    "        angle_rates = pos_indices.unsqueeze(1) / div_term\n",
    "        \n",
    "        # Initialize the positional encoding matrix and apply sine to even \n",
    "        # indices and cosine to odd indices.\n",
    "        pos_encoding = torch.zeros_like(angle_rates)\n",
    "        pos_encoding[:, 0::2] = torch.sin(angle_rates[:, 0::2])\n",
    "        pos_encoding[:, 1::2] = torch.cos(angle_rates[:, 1::2])\n",
    "        \n",
    "        self.position_encoding = pos_encoding\n",
    "\n",
    "    def forward(self):\n",
    "        return self.position_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62284700-3075-4150-916c-69431e5a4abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
       "          0.0000e+00,  1.0000e+00],\n",
       "        [ 8.4147e-01,  5.4030e-01,  8.2186e-01,  ...,  1.0000e+00,\n",
       "          1.0366e-04,  1.0000e+00],\n",
       "        [ 9.0930e-01, -4.1615e-01,  9.3641e-01,  ...,  1.0000e+00,\n",
       "          2.0733e-04,  1.0000e+00],\n",
       "        ...,\n",
       "        [ 1.7612e-02, -9.9984e-01, -9.9954e-01,  ...,  9.9399e-01,\n",
       "          1.0564e-01,  9.9440e-01],\n",
       "        [-8.3182e-01, -5.5504e-01, -5.4457e-01,  ...,  9.9398e-01,\n",
       "          1.0575e-01,  9.9439e-01],\n",
       "        [-9.1649e-01,  4.0007e-01,  3.7906e-01,  ...,  9.9396e-01,\n",
       "          1.0585e-01,  9.9438e-01]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PositionalEncode()()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6040cf9c-47b1-45e9-89f0-ca8249e9a737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
